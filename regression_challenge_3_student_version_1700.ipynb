{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "version": "3.5.2",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "name": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "regression_challenge_3_student_version-1700.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqWaVQ5NIHfo",
        "colab_type": "text"
      },
      "source": [
        "# Linear Regression on the World Population\n",
        "Â© Explore Data Science Academy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns9El0DAIHfp",
        "colab_type": "text"
      },
      "source": [
        "Now that we know about cleaning and exploring a dataset, we will now train a simple linear regression model on a set of data. We'll use the world population data from the Analyse Exam."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG1S4V_pIHfq",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Honour Code\n",
        "\n",
        "I **Kudakwashe Mathew**, **Nhari**, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the EDSA honour code (https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
        "\n",
        "Non-compliance with the honour code constitutes a material breach of contract.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-W97JgcIHfr",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifJiwGfiIHfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_gfes9oIHfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_pop = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/AnalyseProject/world_population.csv')\n",
        "country_map_df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/AnalyseProject/country_code_map.csv', index_col='Country Code')"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s92iCOhlIHfz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "50bd7550-b228-4316-812c-04d1c4c24bf0"
      },
      "source": [
        "df_pop.head()"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country Code</th>\n",
              "      <th>1960</th>\n",
              "      <th>1961</th>\n",
              "      <th>1962</th>\n",
              "      <th>1963</th>\n",
              "      <th>1964</th>\n",
              "      <th>1965</th>\n",
              "      <th>1966</th>\n",
              "      <th>1967</th>\n",
              "      <th>1968</th>\n",
              "      <th>1969</th>\n",
              "      <th>1970</th>\n",
              "      <th>1971</th>\n",
              "      <th>1972</th>\n",
              "      <th>1973</th>\n",
              "      <th>1974</th>\n",
              "      <th>1975</th>\n",
              "      <th>1976</th>\n",
              "      <th>1977</th>\n",
              "      <th>1978</th>\n",
              "      <th>1979</th>\n",
              "      <th>1980</th>\n",
              "      <th>1981</th>\n",
              "      <th>1982</th>\n",
              "      <th>1983</th>\n",
              "      <th>1984</th>\n",
              "      <th>1985</th>\n",
              "      <th>1986</th>\n",
              "      <th>1987</th>\n",
              "      <th>1988</th>\n",
              "      <th>1989</th>\n",
              "      <th>1990</th>\n",
              "      <th>1991</th>\n",
              "      <th>1992</th>\n",
              "      <th>1993</th>\n",
              "      <th>1994</th>\n",
              "      <th>1995</th>\n",
              "      <th>1996</th>\n",
              "      <th>1997</th>\n",
              "      <th>1998</th>\n",
              "      <th>1999</th>\n",
              "      <th>2000</th>\n",
              "      <th>2001</th>\n",
              "      <th>2002</th>\n",
              "      <th>2003</th>\n",
              "      <th>2004</th>\n",
              "      <th>2005</th>\n",
              "      <th>2006</th>\n",
              "      <th>2007</th>\n",
              "      <th>2008</th>\n",
              "      <th>2009</th>\n",
              "      <th>2010</th>\n",
              "      <th>2011</th>\n",
              "      <th>2012</th>\n",
              "      <th>2013</th>\n",
              "      <th>2014</th>\n",
              "      <th>2015</th>\n",
              "      <th>2016</th>\n",
              "      <th>2017</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ABW</td>\n",
              "      <td>54211.0</td>\n",
              "      <td>55438.0</td>\n",
              "      <td>56225.0</td>\n",
              "      <td>56695.0</td>\n",
              "      <td>57032.0</td>\n",
              "      <td>57360.0</td>\n",
              "      <td>57715.0</td>\n",
              "      <td>58055.0</td>\n",
              "      <td>58386.0</td>\n",
              "      <td>58726.0</td>\n",
              "      <td>59063.0</td>\n",
              "      <td>59440.0</td>\n",
              "      <td>59840.0</td>\n",
              "      <td>60243.0</td>\n",
              "      <td>60528.0</td>\n",
              "      <td>60657.0</td>\n",
              "      <td>60586.0</td>\n",
              "      <td>60366.0</td>\n",
              "      <td>60103.0</td>\n",
              "      <td>59980.0</td>\n",
              "      <td>60096.0</td>\n",
              "      <td>60567.0</td>\n",
              "      <td>61345.0</td>\n",
              "      <td>62201.0</td>\n",
              "      <td>62836.0</td>\n",
              "      <td>63026.0</td>\n",
              "      <td>62644.0</td>\n",
              "      <td>61833.0</td>\n",
              "      <td>61079.0</td>\n",
              "      <td>61032.0</td>\n",
              "      <td>62149.0</td>\n",
              "      <td>64622.0</td>\n",
              "      <td>68235.0</td>\n",
              "      <td>72504.0</td>\n",
              "      <td>76700.0</td>\n",
              "      <td>80324.0</td>\n",
              "      <td>83200.0</td>\n",
              "      <td>85451.0</td>\n",
              "      <td>87277.0</td>\n",
              "      <td>89005.0</td>\n",
              "      <td>90853.0</td>\n",
              "      <td>92898.0</td>\n",
              "      <td>94992.0</td>\n",
              "      <td>97017.0</td>\n",
              "      <td>98737.0</td>\n",
              "      <td>100031.0</td>\n",
              "      <td>100832.0</td>\n",
              "      <td>101220.0</td>\n",
              "      <td>101353.0</td>\n",
              "      <td>101453.0</td>\n",
              "      <td>101669.0</td>\n",
              "      <td>102053.0</td>\n",
              "      <td>102577.0</td>\n",
              "      <td>103187.0</td>\n",
              "      <td>103795.0</td>\n",
              "      <td>104341.0</td>\n",
              "      <td>104822.0</td>\n",
              "      <td>105264.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AFG</td>\n",
              "      <td>8996351.0</td>\n",
              "      <td>9166764.0</td>\n",
              "      <td>9345868.0</td>\n",
              "      <td>9533954.0</td>\n",
              "      <td>9731361.0</td>\n",
              "      <td>9938414.0</td>\n",
              "      <td>10152331.0</td>\n",
              "      <td>10372630.0</td>\n",
              "      <td>10604346.0</td>\n",
              "      <td>10854428.0</td>\n",
              "      <td>11126123.0</td>\n",
              "      <td>11417825.0</td>\n",
              "      <td>11721940.0</td>\n",
              "      <td>12027822.0</td>\n",
              "      <td>12321541.0</td>\n",
              "      <td>12590286.0</td>\n",
              "      <td>12840299.0</td>\n",
              "      <td>13067538.0</td>\n",
              "      <td>13237734.0</td>\n",
              "      <td>13306695.0</td>\n",
              "      <td>13248370.0</td>\n",
              "      <td>13053954.0</td>\n",
              "      <td>12749645.0</td>\n",
              "      <td>12389269.0</td>\n",
              "      <td>12047115.0</td>\n",
              "      <td>11783050.0</td>\n",
              "      <td>11601041.0</td>\n",
              "      <td>11502761.0</td>\n",
              "      <td>11540888.0</td>\n",
              "      <td>11777609.0</td>\n",
              "      <td>12249114.0</td>\n",
              "      <td>12993657.0</td>\n",
              "      <td>13981231.0</td>\n",
              "      <td>15095099.0</td>\n",
              "      <td>16172719.0</td>\n",
              "      <td>17099541.0</td>\n",
              "      <td>17822884.0</td>\n",
              "      <td>18381605.0</td>\n",
              "      <td>18863999.0</td>\n",
              "      <td>19403676.0</td>\n",
              "      <td>20093756.0</td>\n",
              "      <td>20966463.0</td>\n",
              "      <td>21979923.0</td>\n",
              "      <td>23064851.0</td>\n",
              "      <td>24118979.0</td>\n",
              "      <td>25070798.0</td>\n",
              "      <td>25893450.0</td>\n",
              "      <td>26616792.0</td>\n",
              "      <td>27294031.0</td>\n",
              "      <td>28004331.0</td>\n",
              "      <td>28803167.0</td>\n",
              "      <td>29708599.0</td>\n",
              "      <td>30696958.0</td>\n",
              "      <td>31731688.0</td>\n",
              "      <td>32758020.0</td>\n",
              "      <td>33736494.0</td>\n",
              "      <td>34656032.0</td>\n",
              "      <td>35530081.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AGO</td>\n",
              "      <td>5643182.0</td>\n",
              "      <td>5753024.0</td>\n",
              "      <td>5866061.0</td>\n",
              "      <td>5980417.0</td>\n",
              "      <td>6093321.0</td>\n",
              "      <td>6203299.0</td>\n",
              "      <td>6309770.0</td>\n",
              "      <td>6414995.0</td>\n",
              "      <td>6523791.0</td>\n",
              "      <td>6642632.0</td>\n",
              "      <td>6776381.0</td>\n",
              "      <td>6927269.0</td>\n",
              "      <td>7094834.0</td>\n",
              "      <td>7277960.0</td>\n",
              "      <td>7474338.0</td>\n",
              "      <td>7682479.0</td>\n",
              "      <td>7900997.0</td>\n",
              "      <td>8130988.0</td>\n",
              "      <td>8376147.0</td>\n",
              "      <td>8641521.0</td>\n",
              "      <td>8929900.0</td>\n",
              "      <td>9244507.0</td>\n",
              "      <td>9582156.0</td>\n",
              "      <td>9931562.0</td>\n",
              "      <td>10277321.0</td>\n",
              "      <td>10609042.0</td>\n",
              "      <td>10921037.0</td>\n",
              "      <td>11218268.0</td>\n",
              "      <td>11513968.0</td>\n",
              "      <td>11827237.0</td>\n",
              "      <td>12171441.0</td>\n",
              "      <td>12553446.0</td>\n",
              "      <td>12968345.0</td>\n",
              "      <td>13403734.0</td>\n",
              "      <td>13841301.0</td>\n",
              "      <td>14268994.0</td>\n",
              "      <td>14682284.0</td>\n",
              "      <td>15088981.0</td>\n",
              "      <td>15504318.0</td>\n",
              "      <td>15949766.0</td>\n",
              "      <td>16440924.0</td>\n",
              "      <td>16983266.0</td>\n",
              "      <td>17572649.0</td>\n",
              "      <td>18203369.0</td>\n",
              "      <td>18865716.0</td>\n",
              "      <td>19552542.0</td>\n",
              "      <td>20262399.0</td>\n",
              "      <td>20997687.0</td>\n",
              "      <td>21759420.0</td>\n",
              "      <td>22549547.0</td>\n",
              "      <td>23369131.0</td>\n",
              "      <td>24218565.0</td>\n",
              "      <td>25096150.0</td>\n",
              "      <td>25998340.0</td>\n",
              "      <td>26920466.0</td>\n",
              "      <td>27859305.0</td>\n",
              "      <td>28813463.0</td>\n",
              "      <td>29784193.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ALB</td>\n",
              "      <td>1608800.0</td>\n",
              "      <td>1659800.0</td>\n",
              "      <td>1711319.0</td>\n",
              "      <td>1762621.0</td>\n",
              "      <td>1814135.0</td>\n",
              "      <td>1864791.0</td>\n",
              "      <td>1914573.0</td>\n",
              "      <td>1965598.0</td>\n",
              "      <td>2022272.0</td>\n",
              "      <td>2081695.0</td>\n",
              "      <td>2135479.0</td>\n",
              "      <td>2187853.0</td>\n",
              "      <td>2243126.0</td>\n",
              "      <td>2296752.0</td>\n",
              "      <td>2350124.0</td>\n",
              "      <td>2404831.0</td>\n",
              "      <td>2458526.0</td>\n",
              "      <td>2513546.0</td>\n",
              "      <td>2566266.0</td>\n",
              "      <td>2617832.0</td>\n",
              "      <td>2671997.0</td>\n",
              "      <td>2726056.0</td>\n",
              "      <td>2784278.0</td>\n",
              "      <td>2843960.0</td>\n",
              "      <td>2904429.0</td>\n",
              "      <td>2964762.0</td>\n",
              "      <td>3022635.0</td>\n",
              "      <td>3083605.0</td>\n",
              "      <td>3142336.0</td>\n",
              "      <td>3227943.0</td>\n",
              "      <td>3286542.0</td>\n",
              "      <td>3266790.0</td>\n",
              "      <td>3247039.0</td>\n",
              "      <td>3227287.0</td>\n",
              "      <td>3207536.0</td>\n",
              "      <td>3187784.0</td>\n",
              "      <td>3168033.0</td>\n",
              "      <td>3148281.0</td>\n",
              "      <td>3128530.0</td>\n",
              "      <td>3108778.0</td>\n",
              "      <td>3089027.0</td>\n",
              "      <td>3060173.0</td>\n",
              "      <td>3051010.0</td>\n",
              "      <td>3039616.0</td>\n",
              "      <td>3026939.0</td>\n",
              "      <td>3011487.0</td>\n",
              "      <td>2992547.0</td>\n",
              "      <td>2970017.0</td>\n",
              "      <td>2947314.0</td>\n",
              "      <td>2927519.0</td>\n",
              "      <td>2913021.0</td>\n",
              "      <td>2905195.0</td>\n",
              "      <td>2900401.0</td>\n",
              "      <td>2895092.0</td>\n",
              "      <td>2889104.0</td>\n",
              "      <td>2880703.0</td>\n",
              "      <td>2876101.0</td>\n",
              "      <td>2873457.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AND</td>\n",
              "      <td>13411.0</td>\n",
              "      <td>14375.0</td>\n",
              "      <td>15370.0</td>\n",
              "      <td>16412.0</td>\n",
              "      <td>17469.0</td>\n",
              "      <td>18549.0</td>\n",
              "      <td>19647.0</td>\n",
              "      <td>20758.0</td>\n",
              "      <td>21890.0</td>\n",
              "      <td>23058.0</td>\n",
              "      <td>24276.0</td>\n",
              "      <td>25559.0</td>\n",
              "      <td>26892.0</td>\n",
              "      <td>28232.0</td>\n",
              "      <td>29520.0</td>\n",
              "      <td>30705.0</td>\n",
              "      <td>31777.0</td>\n",
              "      <td>32771.0</td>\n",
              "      <td>33737.0</td>\n",
              "      <td>34818.0</td>\n",
              "      <td>36067.0</td>\n",
              "      <td>37500.0</td>\n",
              "      <td>39114.0</td>\n",
              "      <td>40867.0</td>\n",
              "      <td>42706.0</td>\n",
              "      <td>44600.0</td>\n",
              "      <td>46517.0</td>\n",
              "      <td>48455.0</td>\n",
              "      <td>50434.0</td>\n",
              "      <td>52448.0</td>\n",
              "      <td>54509.0</td>\n",
              "      <td>56671.0</td>\n",
              "      <td>58888.0</td>\n",
              "      <td>60971.0</td>\n",
              "      <td>62677.0</td>\n",
              "      <td>63850.0</td>\n",
              "      <td>64360.0</td>\n",
              "      <td>64327.0</td>\n",
              "      <td>64142.0</td>\n",
              "      <td>64370.0</td>\n",
              "      <td>65390.0</td>\n",
              "      <td>67341.0</td>\n",
              "      <td>70049.0</td>\n",
              "      <td>73182.0</td>\n",
              "      <td>76244.0</td>\n",
              "      <td>78867.0</td>\n",
              "      <td>80991.0</td>\n",
              "      <td>82683.0</td>\n",
              "      <td>83861.0</td>\n",
              "      <td>84462.0</td>\n",
              "      <td>84449.0</td>\n",
              "      <td>83751.0</td>\n",
              "      <td>82431.0</td>\n",
              "      <td>80788.0</td>\n",
              "      <td>79223.0</td>\n",
              "      <td>78014.0</td>\n",
              "      <td>77281.0</td>\n",
              "      <td>76965.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Country Code       1960       1961  ...        2015        2016        2017\n",
              "0          ABW    54211.0    55438.0  ...    104341.0    104822.0    105264.0\n",
              "1          AFG  8996351.0  9166764.0  ...  33736494.0  34656032.0  35530081.0\n",
              "2          AGO  5643182.0  5753024.0  ...  27859305.0  28813463.0  29784193.0\n",
              "3          ALB  1608800.0  1659800.0  ...   2880703.0   2876101.0   2873457.0\n",
              "4          AND    13411.0    14375.0  ...     78014.0     77281.0     76965.0\n",
              "\n",
              "[5 rows x 59 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR70v9YjIHf4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "1f0d29fc-2d80-4b1e-a143-ae0d663578ec"
      },
      "source": [
        "country_map_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country Name</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Country Code</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ABW</th>\n",
              "      <td>Aruba</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AFG</th>\n",
              "      <td>Afghanistan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AGO</th>\n",
              "      <td>Angola</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ALB</th>\n",
              "      <td>Albania</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AND</th>\n",
              "      <td>Andorra</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Country Name\n",
              "Country Code             \n",
              "ABW                 Aruba\n",
              "AFG           Afghanistan\n",
              "AGO                Angola\n",
              "ALB               Albania\n",
              "AND               Andorra"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAluAOfCIHf8",
        "colab_type": "text"
      },
      "source": [
        "## Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxE0EqI5IHf9",
        "colab_type": "text"
      },
      "source": [
        "### Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NZUOTPAIHf-",
        "colab_type": "text"
      },
      "source": [
        "The world population data spans from 1960 to 2017. We'd like to build a predictive model that can give us the best guess at what the future or past population of a particular country was or might be.\n",
        "\n",
        "First, however, we need to formulate our data such that sklearn's `Ridge` regression class can train on our data. To do this, we will write a function that takes as input a country name and return a 2-d numpy array that contains the year and the measured population. \n",
        "\n",
        "_**Function Specifications:**_\n",
        "* Should take a `str` as input and return a numpy `array` type as output.\n",
        "* The array should only have two columns containing the year and the population, in other words, it should have a shape `(?, 2)` where `?` is the length of the data.\n",
        "* The values within the array should be of type `int`.\n",
        "\n",
        "_**Hint:**_\n",
        "You'll need to use both the the population and country map dataframes given above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shZgWDOFIHf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### START FUNCTION\n",
        "def get_year_pop(country_name):\n",
        "  \"\"\"takes as input a country name and return a 2-d numpy array that contains the year and the measured population.\"\"\"\n",
        "  \n",
        "  index = list(country_map_df[country_map_df['Country Name'] == country_name].index)\n",
        "  df = df_pop[df_pop['Country Code'] == index[0]]\n",
        "  df_melted = pd.melt(df, id_vars=[\"Country Code\"])\n",
        "  df_droped = df_melted.drop('Country Code',axis=1)\n",
        "  df_int = df_droped.astype('int')\n",
        "  ary = np.array(df_int)\n",
        "  return ary\n",
        "\n",
        "### END FUNCTION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJdyf6psIHgC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a64b2cba-db95-4843-9f90-cb62cfa89418"
      },
      "source": [
        "get_year_pop('Aruba')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  1960,  54211],\n",
              "       [  1961,  55438],\n",
              "       [  1962,  56225],\n",
              "       [  1963,  56695],\n",
              "       [  1964,  57032],\n",
              "       [  1965,  57360],\n",
              "       [  1966,  57715],\n",
              "       [  1967,  58055],\n",
              "       [  1968,  58386],\n",
              "       [  1969,  58726],\n",
              "       [  1970,  59063],\n",
              "       [  1971,  59440],\n",
              "       [  1972,  59840],\n",
              "       [  1973,  60243],\n",
              "       [  1974,  60528],\n",
              "       [  1975,  60657],\n",
              "       [  1976,  60586],\n",
              "       [  1977,  60366],\n",
              "       [  1978,  60103],\n",
              "       [  1979,  59980],\n",
              "       [  1980,  60096],\n",
              "       [  1981,  60567],\n",
              "       [  1982,  61345],\n",
              "       [  1983,  62201],\n",
              "       [  1984,  62836],\n",
              "       [  1985,  63026],\n",
              "       [  1986,  62644],\n",
              "       [  1987,  61833],\n",
              "       [  1988,  61079],\n",
              "       [  1989,  61032],\n",
              "       [  1990,  62149],\n",
              "       [  1991,  64622],\n",
              "       [  1992,  68235],\n",
              "       [  1993,  72504],\n",
              "       [  1994,  76700],\n",
              "       [  1995,  80324],\n",
              "       [  1996,  83200],\n",
              "       [  1997,  85451],\n",
              "       [  1998,  87277],\n",
              "       [  1999,  89005],\n",
              "       [  2000,  90853],\n",
              "       [  2001,  92898],\n",
              "       [  2002,  94992],\n",
              "       [  2003,  97017],\n",
              "       [  2004,  98737],\n",
              "       [  2005, 100031],\n",
              "       [  2006, 100832],\n",
              "       [  2007, 101220],\n",
              "       [  2008, 101353],\n",
              "       [  2009, 101453],\n",
              "       [  2010, 101669],\n",
              "       [  2011, 102053],\n",
              "       [  2012, 102577],\n",
              "       [  2013, 103187],\n",
              "       [  2014, 103795],\n",
              "       [  2015, 104341],\n",
              "       [  2016, 104822],\n",
              "       [  2017, 105264]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlWk2VP6IHgH",
        "colab_type": "text"
      },
      "source": [
        "_**Expected Outputs:**_\n",
        "```python\n",
        "get_year_pop('Aruba')\n",
        "```\n",
        "> ```\n",
        "array([[  1960,  54211],\n",
        "       [  1961,  55438],\n",
        "       [  1962,  56225],\n",
        "        ...\n",
        "       [  2016, 104822],\n",
        "       [  2017, 105264]])\n",
        "```\n",
        "\n",
        "```python\n",
        "get_year_pop('Aruba').shape == (58, 2)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGbCrXlvIHgJ",
        "colab_type": "text"
      },
      "source": [
        "### Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDzPZIZjIHgJ",
        "colab_type": "text"
      },
      "source": [
        "Now that we have have our data, we need to split this into a training set, and a testing set. But before we split our data into training and testing, we also need to split our data into the predictive features (denoted `X`) and the response (denoted `y`). \n",
        "\n",
        "Write a function that will take as input a 2-d numpy array and return four variables in the form of `(X_train, y_train), (X_test, y_test)`, where `(X_train, y_train)` are the features + response of the training set, and `(X-test, y_test)` are the features + response of the testing set.\n",
        "\n",
        "_**Function Specifications:**_\n",
        "* Should take a 2-d numpy `array` as input.\n",
        "* Should split the array such that X is the year, and y is the corresponding population.\n",
        "* Should return two `tuples` of the form `(X_train, y_train), (X_test, y_test)`.\n",
        "* Should use sklearn's train_test_split function with a `test_size = 0.2` and `random_state = 42`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SKpi_NjIHgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### START FUNCTION\n",
        "def feature_response_split(arr):\n",
        "  \"\"\"take as input a 2-d numpy array and return four variables in the form of (X_train, y_train), (X_test, y_test)\"\"\"\n",
        "  \n",
        "  X = np.array([item[0] for item in arr])\n",
        "  y = np.array([item[-1] for item in arr])\n",
        "  X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2, random_state = 42)\n",
        "  return (X_train, y_train), (X_test, y_test)\n",
        "\n",
        "### END FUNCTION"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK9sF02HIHgN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "c343f0d0-dd24-4bb6-a98c-183f6db29374"
      },
      "source": [
        "data = get_year_pop('Aruba')\n",
        "feature_response_split(data)"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([1996, 1991, 1968, 1977, 1966, 1964, 2001, 1979, 1990, 2009, 2010,\n",
              "         2014, 1975, 1969, 1987, 1986, 1976, 1984, 1993, 2015, 2000, 1971,\n",
              "         1992, 2016, 2003, 1989, 2013, 1961, 1981, 1962, 2005, 1999, 1995,\n",
              "         1983, 2007, 1970, 1982, 1978, 2017, 1980, 1967, 2002, 1974, 1988,\n",
              "         2011, 1998]),\n",
              "  array([ 83200,  64622,  58386,  60366,  57715,  57032,  92898,  59980,\n",
              "          62149, 101453, 101669, 103795,  60657,  58726,  61833,  62644,\n",
              "          60586,  62836,  72504, 104341,  90853,  59440,  68235, 104822,\n",
              "          97017,  61032, 103187,  55438,  60567,  56225, 100031,  89005,\n",
              "          80324,  62201, 101220,  59063,  61345,  60103, 105264,  60096,\n",
              "          58055,  94992,  60528,  61079, 102053,  87277])),\n",
              " (array([1960, 1965, 1994, 1973, 2004, 2012, 1997, 1985, 2006, 1972, 2008,\n",
              "         1963]),\n",
              "  array([ 54211,  57360,  76700,  60243,  98737, 102577,  85451,  63026,\n",
              "         100832,  59840, 101353,  56695])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RMBWD0FIHgR",
        "colab_type": "text"
      },
      "source": [
        "_**Expected Outputs:**_\n",
        "```python\n",
        "data = get_year_pop('Aruba')\n",
        "feature_response_split(data)\n",
        "```\n",
        "> \n",
        "```\n",
        "X_train == array([1996, 1991, 1968, 1977, 1966, 1964, 2001, 1979, 1990, 2009, 2010,\n",
        "       2014, 1975, 1969, 1987, 1986, 1976, 1984, 1993, 2015, 2000, 1971,\n",
        "       1992, 2016, 2003, 1989, 2013, 1961, 1981, 1962, 2005, 1999, 1995,\n",
        "       1983, 2007, 1970, 1982, 1978, 2017, 1980, 1967, 2002, 1974, 1988,\n",
        "       2011, 1998])\n",
        "\n",
        "y_train == array([ 83200,  64622,  58386,  60366,  57715,  57032,  92898,  59980,\n",
        "        62149, 101453, 101669, 103795,  60657,  58726,  61833,  62644,\n",
        "        60586,  62836,  72504, 104341,  90853,  59440,  68235, 104822,\n",
        "        97017,  61032, 103187,  55438,  60567,  56225, 100031,  89005,\n",
        "        80324,  62201, 101220,  59063,  61345,  60103, 105264,  60096,\n",
        "        58055,  94992,  60528,  61079, 102053,  87277])\n",
        "        \n",
        "X_test == array([1960, 1965, 1994, 1973, 2004, 2012, 1997, 1985, 2006, 1972, 2008,\n",
        "       1963])\n",
        "       \n",
        "y_test == array([ 54211,  57360,  76700,  60243,  98737, 102577,  85451,  63026,\n",
        "       100832,  59840, 101353,  56695])\n",
        " ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXLV3ggrIHgR",
        "colab_type": "text"
      },
      "source": [
        "### Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmHvolDEIHgS",
        "colab_type": "text"
      },
      "source": [
        "Now that we have formatted our data, we can fit a model using sklearn's `Ridge()` class. We'll write a function that will take as input the features and response variables that we created in the last question, and returns a trained model.\n",
        "\n",
        "_**Function Specifications:**_\n",
        "* Should take two numpy `arrays` as input in the form `(X_train, y_train)`.\n",
        "* Should return an sklearn `Ridge` model.\n",
        "* The returned model should be fitted to the data.\n",
        "\n",
        "_**Hint:**_\n",
        "You may need to reshape the data within the function. You can use `.reshape(-1, 1)` to do this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKYeuSUIIHgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### START FUNCTION\n",
        "def train_model(X_train, y_train):\n",
        "  \"\"\"take as input the features and response variables and returns a trained model.\"\"\"\n",
        "\n",
        "  X_train = X_train.reshape(-1,1)\n",
        "  y_train = y_train.reshape(-1,1)\n",
        "  ridge = Ridge()\n",
        "  model = ridge.fit(X_train, y_train)\n",
        "  return model\n",
        "\n",
        "### END FUNCTION"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI1GETreIHgd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "066b7d17-e4af-4e78-ec75-1a8a78d3c36c"
      },
      "source": [
        "data = get_year_pop('Aruba')\n",
        "(X_train, y_train), _ = feature_response_split(data)\n",
        "\n",
        "train_model(X_train, y_train).predict([[2017]])"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[104468.15547163]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liGhpGaIIHgg",
        "colab_type": "text"
      },
      "source": [
        "_**Expected Outputs:**_\n",
        "```python\n",
        "train_model(X_train, y_train).predict([[2017]]) == array([[104468.15547163]])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3jPtRkkIHgh",
        "colab_type": "text"
      },
      "source": [
        "### Question 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3-IZy1eIHgi",
        "colab_type": "text"
      },
      "source": [
        "We would now like to test our model using the testing data that we produced from Question 2. To chieve this, we'll use the mean square error, which for your convenience is written as:\n",
        "$$\n",
        "MSE = \\frac{1}{N}\\sum_{i=1}^N (p_i - y_i)^2,\n",
        "$$\n",
        "where $p_i$ refers to the $i^{\\rm th}$ prediction made from `X_test`, $y_i$ refers to the $i^{\\rm th}$ value in `y_test`, and $N$ is the length of `y_test`.\n",
        "\n",
        "_**Function Specifications:**_\n",
        "* Should take a trained model and two `arrays` as input. This will be the `X_test` and `y_test` variables from Question 2. \n",
        "* Should return the mean square error over the input from the predicted values of `X_test` as compared to values of `y_test`.\n",
        "* The output should be a `float` rounded to 2 decimal places."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4K6u41cIHgi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### START FUNCTION\n",
        "def test_model(model, X_test, y_test):\n",
        "  X_test = X_test.reshape(-1,1)\n",
        "  y_test = y_test.reshape(-1,1)\n",
        "  prediction = model.predict(X_test)\n",
        "  MSE = round((1/len(y_test))*((prediction - y_test) ** 2).sum(), 2)\n",
        "  return MSE\n",
        "\n",
        "### END FUNCTION"
      ],
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIWbw5u-IHgl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ccd68e9-434b-44ff-f051-75d7a55eb30f"
      },
      "source": [
        "data = get_year_pop('Aruba')\n",
        "(X_train, y_train), (X_test, y_test) = feature_response_split(data)\n",
        "lm = train_model(X_train, y_train)\n",
        "\n",
        "test_model(lm, X_test, y_test)"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42483684.58"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiU9vbq5IHgo",
        "colab_type": "text"
      },
      "source": [
        "_**Expected Outputs:**_\n",
        "```python\n",
        "test_model(lm, X_test, y_test) == 42483684.58\n",
        "```"
      ]
    }
  ]
}